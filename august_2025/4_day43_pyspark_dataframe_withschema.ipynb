{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23e7cb5b-b746-4df4-8b7f-64b904c4d328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4_day43_pyspark_dataframe_withschema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff8bc97-b5f4-4b87-bbcd-5896ae189457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# create dataframe list values with schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4c31284-9fbc-4a8c-965b-fe07a31137d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# this step is optional in databricks\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('dfclass').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e0f3ff7-bd58-4836-96bf-243216edbd0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_values = [(1,'java', 2000), (2,'python', 3000), (3,'scala', 4000)]\n",
    "df =  spark.createDataFrame(data = list_values,schema = ['id','language','fee'])\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05c2f6f7-6e12-4268-b511-02f09b0702c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_values = [(1,'java',2000),(2,'python',3000),(3,'scala',4000),(5,'java',2000),(6,'python',3000),(7,'scala',4000)]\n",
    "\n",
    "\n",
    "schema =  \"id int, language string, fee float\"\n",
    "df = spark.createDataFrame(data=list_values,schema= schema, samplingRatio=0.7)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b70864-3838-4019-a1d7-d91d33a1221c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17878a89-128b-419a-9926-aadaac79c69d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1406b61-94c5-4db1-b0b5-f61779c15a74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType,FloatType\n",
    "list_values = [(1,200,2000),(2,'python',3000.0),(3,'scala',4000.0)]\n",
    "\n",
    "schema = StructType([StructField(name='id', dataType=IntegerType(), nullable=False), \n",
    "                     StructField(name='language', dataType= StringType(), nullable=True), \n",
    "                     StructField(name= 'fee', dataType=FloatType(), nullable=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c723f123-d60a-4287-8363-5e2157164d09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_withschema = spark.createDataFrame(data=list_values,schema= schema)\n",
    "df_withschema.show()\n",
    "df_withschema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d99b9f3-1980-463b-be2e-4ee4ec363fbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#####  ('one',200,2000)--- > datatype is integer and i put in string show the error\n",
    "###### ArrowInvalid: Could not convert 'one' with type str: tried to convert to int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d82183e-5707-4b45-87c6-4fad3b960d5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_values = [('one',200,2000),(2,'python',3000.0),(3,'scala',4000.0)]\n",
    "\n",
    "schema = StructType([StructField(name='id', dataType=IntegerType(), nullable=False), \n",
    "                     StructField(name='language', dataType= StringType(), nullable=True), \n",
    "                     StructField(name= 'fee', dataType=FloatType(), nullable=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c795efea-65cd-4eab-a532-0ee31991c7c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_withschema = spark.createDataFrame(data=list_values,schema= schema)\n",
    "df_withschema.show()\n",
    "df_withschema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8992f72d-a824-42e4-9e49-b1ed915831cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### (None,200,2000) ---> nullable = false and i put here \"None\" show error ( Do not accept None values)\n",
    "###### PySparkValueError: input for IntegerType() must not be None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c6c79d-8194-4f21-afe3-6bf339cd15dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_values = [(None,200,2000),(2,'python',3000.0),(3,'scala',4000.0)]\n",
    "\n",
    "schema = StructType([StructField(name='id', dataType=IntegerType(), nullable=False), \n",
    "                     StructField(name='language', dataType= StringType(), nullable=True), \n",
    "                     StructField(name= 'fee', dataType=FloatType(), nullable=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54479786-d471-4d81-aede-b8b51409d54a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_withschema = spark.createDataFrame(data=list_values,schema= schema)\n",
    "df_withschema.show()\n",
    "df_withschema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "448c8a0a-095d-49e9-80b2-2114c7bb03dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_values = [(None,200,2000),(2,'python',3000.0),(3,'scala',4000.0)]\n",
    "\n",
    "schema = StructType([StructField(name='id', dataType=IntegerType(), nullable=True), \n",
    "                     StructField(name='language', dataType= StringType(), nullable=True), \n",
    "                     StructField(name= 'fee', dataType=FloatType(), nullable=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8026abaf-61d2-4e1a-83b4-c00110b85ae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_withschema = spark.createDataFrame(data=list_values,schema= schema)\n",
    "df_withschema.show()\n",
    "df_withschema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c95b7082-6b4a-44a3-9a12-d272511cf180",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_withschema.filter(\"id > 1\").display()\n",
    "\n",
    "df_withschema.createOrReplaceTempView(\"df_v\")\n",
    "spark.sql(\"select id, count(1) from df_v group by id having count(1)>1 \").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e41c611-5d08-4345-b74e-9135f275a101",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_day43_pyspark_dataframe_withschema",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
